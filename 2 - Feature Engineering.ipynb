{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading and splitting the data\n",
    "\n",
    "In this notebook we will first load and split the data into train, test and labels to pass into our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('normalised_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>shangai</th>\n",
       "      <th>btc</th>\n",
       "      <th>crude oil</th>\n",
       "      <th>dax</th>\n",
       "      <th>euro</th>\n",
       "      <th>gold</th>\n",
       "      <th>silver</th>\n",
       "      <th>spy</th>\n",
       "      <th>ftse</th>\n",
       "      <th>hsi</th>\n",
       "      <th>...</th>\n",
       "      <th>MA200</th>\n",
       "      <th>stochRSI</th>\n",
       "      <th>RSI</th>\n",
       "      <th>btc_std_dev</th>\n",
       "      <th>std_dif</th>\n",
       "      <th>conf_int</th>\n",
       "      <th>hashrate</th>\n",
       "      <th>difficulty</th>\n",
       "      <th>transactions</th>\n",
       "      <th>t_cost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2778.000000</td>\n",
       "      <td>2778.000000</td>\n",
       "      <td>2778.000000</td>\n",
       "      <td>1665.000000</td>\n",
       "      <td>2778.000000</td>\n",
       "      <td>2778.000000</td>\n",
       "      <td>2778.000000</td>\n",
       "      <td>2778.000000</td>\n",
       "      <td>2778.000000</td>\n",
       "      <td>2778.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2691.000000</td>\n",
       "      <td>2691.000000</td>\n",
       "      <td>2691.000000</td>\n",
       "      <td>2691.000000</td>\n",
       "      <td>2691.000000</td>\n",
       "      <td>2691.000000</td>\n",
       "      <td>2.778000e+03</td>\n",
       "      <td>2.778000e+03</td>\n",
       "      <td>2778.000000</td>\n",
       "      <td>2778.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.270252</td>\n",
       "      <td>0.154850</td>\n",
       "      <td>0.701774</td>\n",
       "      <td>0.568666</td>\n",
       "      <td>0.394548</td>\n",
       "      <td>0.344136</td>\n",
       "      <td>0.253115</td>\n",
       "      <td>0.427729</td>\n",
       "      <td>0.551747</td>\n",
       "      <td>0.465237</td>\n",
       "      <td>...</td>\n",
       "      <td>0.245285</td>\n",
       "      <td>0.532964</td>\n",
       "      <td>0.583096</td>\n",
       "      <td>0.256707</td>\n",
       "      <td>0.102468</td>\n",
       "      <td>0.097318</td>\n",
       "      <td>1.412163e-01</td>\n",
       "      <td>1.546927e-01</td>\n",
       "      <td>0.303778</td>\n",
       "      <td>0.154293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.160729</td>\n",
       "      <td>0.209940</td>\n",
       "      <td>0.156021</td>\n",
       "      <td>0.157132</td>\n",
       "      <td>0.250220</td>\n",
       "      <td>0.208389</td>\n",
       "      <td>0.189366</td>\n",
       "      <td>0.254075</td>\n",
       "      <td>0.232827</td>\n",
       "      <td>0.184326</td>\n",
       "      <td>...</td>\n",
       "      <td>0.344058</td>\n",
       "      <td>0.355758</td>\n",
       "      <td>0.195650</td>\n",
       "      <td>0.347463</td>\n",
       "      <td>0.160511</td>\n",
       "      <td>0.149650</td>\n",
       "      <td>2.400142e-01</td>\n",
       "      <td>2.641203e-01</td>\n",
       "      <td>0.315799</td>\n",
       "      <td>0.158696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.128674</td>\n",
       "      <td>0.002796</td>\n",
       "      <td>0.573618</td>\n",
       "      <td>0.461651</td>\n",
       "      <td>0.178477</td>\n",
       "      <td>0.192765</td>\n",
       "      <td>0.121774</td>\n",
       "      <td>0.197647</td>\n",
       "      <td>0.346391</td>\n",
       "      <td>0.339979</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001123</td>\n",
       "      <td>0.202171</td>\n",
       "      <td>0.449066</td>\n",
       "      <td>0.001551</td>\n",
       "      <td>0.000504</td>\n",
       "      <td>0.000889</td>\n",
       "      <td>2.731303e-07</td>\n",
       "      <td>2.424056e-07</td>\n",
       "      <td>0.024813</td>\n",
       "      <td>0.038594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.289271</td>\n",
       "      <td>0.028008</td>\n",
       "      <td>0.655549</td>\n",
       "      <td>0.560341</td>\n",
       "      <td>0.312910</td>\n",
       "      <td>0.267663</td>\n",
       "      <td>0.165405</td>\n",
       "      <td>0.407019</td>\n",
       "      <td>0.572176</td>\n",
       "      <td>0.431315</td>\n",
       "      <td>...</td>\n",
       "      <td>0.045246</td>\n",
       "      <td>0.555324</td>\n",
       "      <td>0.572004</td>\n",
       "      <td>0.062386</td>\n",
       "      <td>0.013058</td>\n",
       "      <td>0.017446</td>\n",
       "      <td>3.126407e-03</td>\n",
       "      <td>3.292851e-03</td>\n",
       "      <td>0.157937</td>\n",
       "      <td>0.075552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.370071</td>\n",
       "      <td>0.333326</td>\n",
       "      <td>0.861095</td>\n",
       "      <td>0.674688</td>\n",
       "      <td>0.624300</td>\n",
       "      <td>0.504672</td>\n",
       "      <td>0.344026</td>\n",
       "      <td>0.654494</td>\n",
       "      <td>0.763450</td>\n",
       "      <td>0.596733</td>\n",
       "      <td>...</td>\n",
       "      <td>0.548718</td>\n",
       "      <td>0.875468</td>\n",
       "      <td>0.727869</td>\n",
       "      <td>0.672941</td>\n",
       "      <td>0.193318</td>\n",
       "      <td>0.183024</td>\n",
       "      <td>2.312814e-01</td>\n",
       "      <td>2.553552e-01</td>\n",
       "      <td>0.560025</td>\n",
       "      <td>0.240591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           shangai          btc    crude oil          dax         euro  \\\n",
       "count  2778.000000  2778.000000  2778.000000  1665.000000  2778.000000   \n",
       "mean      0.270252     0.154850     0.701774     0.568666     0.394548   \n",
       "std       0.160729     0.209940     0.156021     0.157132     0.250220   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.128674     0.002796     0.573618     0.461651     0.178477   \n",
       "50%       0.289271     0.028008     0.655549     0.560341     0.312910   \n",
       "75%       0.370071     0.333326     0.861095     0.674688     0.624300   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "              gold       silver          spy         ftse          hsi  ...  \\\n",
       "count  2778.000000  2778.000000  2778.000000  2778.000000  2778.000000  ...   \n",
       "mean      0.344136     0.253115     0.427729     0.551747     0.465237  ...   \n",
       "std       0.208389     0.189366     0.254075     0.232827     0.184326  ...   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
       "25%       0.192765     0.121774     0.197647     0.346391     0.339979  ...   \n",
       "50%       0.267663     0.165405     0.407019     0.572176     0.431315  ...   \n",
       "75%       0.504672     0.344026     0.654494     0.763450     0.596733  ...   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000  ...   \n",
       "\n",
       "             MA200     stochRSI          RSI  btc_std_dev      std_dif  \\\n",
       "count  2691.000000  2691.000000  2691.000000  2691.000000  2691.000000   \n",
       "mean      0.245285     0.532964     0.583096     0.256707     0.102468   \n",
       "std       0.344058     0.355758     0.195650     0.347463     0.160511   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.001123     0.202171     0.449066     0.001551     0.000504   \n",
       "50%       0.045246     0.555324     0.572004     0.062386     0.013058   \n",
       "75%       0.548718     0.875468     0.727869     0.672941     0.193318   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "          conf_int      hashrate    difficulty  transactions       t_cost  \n",
       "count  2691.000000  2.778000e+03  2.778000e+03   2778.000000  2778.000000  \n",
       "mean      0.097318  1.412163e-01  1.546927e-01      0.303778     0.154293  \n",
       "std       0.149650  2.400142e-01  2.641203e-01      0.315799     0.158696  \n",
       "min       0.000000  0.000000e+00  0.000000e+00      0.000000     0.000000  \n",
       "25%       0.000889  2.731303e-07  2.424056e-07      0.024813     0.038594  \n",
       "50%       0.017446  3.126407e-03  3.292851e-03      0.157937     0.075552  \n",
       "75%       0.183024  2.312814e-01  2.553552e-01      0.560025     0.240591  \n",
       "max       1.000000  1.000000e+00  1.000000e+00      1.000000     1.000000  \n",
       "\n",
       "[8 rows x 25 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = df.btc\n",
    "train_df = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arn:aws:iam::724888201472:role/service-role/AmazonSageMaker-ExecutionRole-20201115T171901\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "session = sagemaker.Session() # store the current SageMaker session\n",
    "\n",
    "# get IAM role\n",
    "role = get_execution_role()\n",
    "print(role)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker-eu-central-1-724888201472\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# get default bucket\n",
    "bucket_name = session.default_bucket()\n",
    "print(bucket_name)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training artifacts will be uploaded to: s3://sagemaker-eu-central-1-724888201472/capstone/\n"
     ]
    }
   ],
   "source": [
    "# define location to store model artifacts\n",
    "prefix = 'capstone'\n",
    "\n",
    "output_path='s3://{}/{}/'.format(bucket_name, prefix)\n",
    "\n",
    "print('Training artifacts will be uploaded to: {}'.format(output_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a PCA model\n",
    "from sagemaker import PCA\n",
    "\n",
    "# this is current features - 1\n",
    "# you'll select only a portion of these to use, later\n",
    "N_COMPONENTS=23\n",
    "\n",
    "pca_model = PCA(role=role,\n",
    "             train_instance_count=1,\n",
    "             train_instance_type='ml.c4.xlarge',\n",
    "             output_path=output_path, # specified, above\n",
    "             num_components=N_COMPONENTS, \n",
    "             sagemaker_session=session)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert df to np array\n",
    "train_data = train_df.values.astype('float32')\n",
    "\n",
    "# convert to RecordSet format\n",
    "record_train = pca_model.record_set(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# train the PCA mode on the formatted data\n",
    "pca_model.fit(record_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the name of the training job, it's suggested that you copy-paste\n",
    "# from the notebook or from a specific job in the AWS console\n",
    "\n",
    "training_job_name='pca-2020-10-06-16-58-17-215' # include one!\n",
    "\n",
    "# where the model is saved, by default\n",
    "model_key = os.path.join(prefix, training_job_name, 'output/model.tar.gz')\n",
    "print(model_key)\n",
    "\n",
    "# download and unzip model\n",
    "boto3.resource('s3').Bucket(bucket_name).download_file(model_key, 'model.tar.gz')\n",
    "\n",
    "# unzipping as pca_capstone\n",
    "os.system('tar -zxvf model.tar.gz')\n",
    "os.system('unzip pca_capstone')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mxnet as mx\n",
    "\n",
    "# loading the unzipped artifacts\n",
    "pca_model_params = mx.ndarray.load('pca_capstone')\n",
    "\n",
    "# what are the params\n",
    "print(pca_model_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get selected params\n",
    "s=pd.DataFrame(pca_model_params['s'].asnumpy())\n",
    "v=pd.DataFrame(pca_model_params['v'].asnumpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the explained variance for the top n principal components\n",
    "# you may assume you have access to the global var N_COMPONENTS\n",
    "def explained_variance(s, n_top_components):\n",
    "    '''Calculates the approx. data variance that n_top_components captures.\n",
    "       :param s: A dataframe of singular values for top components; \n",
    "           the top value is in the last row.\n",
    "       :param n_top_components: An integer, the number of top components to use.\n",
    "       :return: The expected data variance covered by the n_top_components.'''\n",
    "    \n",
    "    start_idx = N_COMPONENTS - n_top_components  ## 33-3 = 30, for example\n",
    "    # calculate approx variance\n",
    "    exp_variance = np.square(s.iloc[start_idx:,:]).sum()/np.square(s).sum()\n",
    "    \n",
    "    return exp_variance[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt_variate = []\n",
    "def plot_variance_ncomp(s, n_top_components, cut=0.8):\n",
    "    for i in range(n_top_components + 1):\n",
    "        alt_variate.append(explained_variance(s, i))\n",
    "        # print(i)\n",
    "        alt_variate_np = np.array(alt_variate)\n",
    "    # print(alt_variate_np)\n",
    "    plt.plot(alt_variate_np, scaley=False)\n",
    "    plt.plot(list(range(n_top_components)),[ cut for i in range(i)], color='red')\n",
    "    plt.show()\n",
    "    print('Explained variance: ', explained_variance(s,n_top_components)[0], 'with',n_top_components,'components')\n",
    "    print('Total components: ', len(s))\n",
    "    \n",
    "plot_variance_ncomp(s, 12, 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features\n",
    "features_list = train_df.columns.values\n",
    "print('Features: \\n', features_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "def display_component(v, features_list, component_num, n_weights=10):\n",
    "    \n",
    "    # get index of component (last row - component_num)\n",
    "    row_idx = N_COMPONENTS-component_num\n",
    "\n",
    "    # get the list of weights from a row in v, dataframe\n",
    "    v_1_row = v.iloc[:, row_idx]\n",
    "    v_1 = np.squeeze(v_1_row.values)\n",
    "\n",
    "    # match weights to features in counties_scaled dataframe, using list comporehension\n",
    "    comps = pd.DataFrame(list(zip(v_1, features_list)), \n",
    "                         columns=['weights', 'features'])\n",
    "\n",
    "    # we'll want to sort by the largest n_weights\n",
    "    # weights can be neg/pos and we'll sort by magnitude\n",
    "    comps['abs_weights']=comps['weights'].apply(lambda x: np.abs(x))\n",
    "    sorted_weight_data = comps.sort_values('abs_weights', ascending=False).head(n_weights)\n",
    "\n",
    "    # display using seaborn\n",
    "    ax=plt.subplots(figsize=(10,6))\n",
    "    ax=sns.barplot(data=sorted_weight_data, \n",
    "                   x=\"weights\", \n",
    "                   y=\"features\", \n",
    "                   palette=\"Blues_d\")\n",
    "    ax.set_title(\"PCA Component Makeup, Component #\" + str(component_num))\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display makeup of first component\n",
    "num=2\n",
    "display_component(v, train_df.columns.values, component_num=num, n_weights=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# this takes a little while, around 7mins\n",
    "pca_predictor = pca_model.deploy(initial_instance_count=1, \n",
    "                              instance_type='ml.t2.medium')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pass np train data to the PCA model\n",
    "train_pca = pca_predictor.predict(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check out the first item in the produced training features\n",
    "data_idx = 0\n",
    "print(train_pca[data_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dimensionality-reduced data\n",
    "def create_transformed_df(train_pca, counties_scaled, n_top_components):\n",
    "    ''' Return a dataframe of data points with component features. \n",
    "        The dataframe should be indexed by State-County and contain component values.\n",
    "        :param train_pca: A list of pca training data, returned by a PCA model.\n",
    "        :param counties_scaled: A dataframe of normalized, original features.\n",
    "        :param n_top_components: An integer, the number of top components to use.\n",
    "        :return: A dataframe, indexed by State-County, with n_top_component values as columns.        \n",
    "     '''\n",
    "    # create new dataframe to add data to\n",
    "    counties_transformed=pd.DataFrame()\n",
    "\n",
    "    # for each of our new, transformed data points\n",
    "    # append the component values to the dataframe\n",
    "    for data in train_pca:\n",
    "        # get component values for each data point\n",
    "        components=data.label['projection'].float32_tensor.values\n",
    "        counties_transformed=counties_transformed.append([list(components)])\n",
    "\n",
    "    # index by county, just like counties_scaled\n",
    "    counties_transformed.index=counties_scaled.index\n",
    "\n",
    "    # keep only the top n components\n",
    "    start_idx = N_COMPONENTS - n_top_components\n",
    "    counties_transformed = counties_transformed.iloc[:,start_idx:]\n",
    "    \n",
    "    # reverse columns, component order     \n",
    "    return counties_transformed.iloc[:, ::-1]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify top n\n",
    "top_n = 7\n",
    "\n",
    "# call your function and create a new dataframe\n",
    "df_transformed = create_transformed_df(train_pca, train_df, n_top_components=top_n)\n",
    "\n",
    "# add descriptive columns\n",
    "PCA_list=['c_1', 'c_2', 'c_3', 'c_4', 'c_5', 'c_6', 'c_7']\n",
    "df_transformed.columns=PCA_list \n",
    "\n",
    "# print result\n",
    "df_transformed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete predictor endpoint\n",
    "session.delete_endpoint(pca_predictor.endpoint)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_mxnet_p36",
   "language": "python",
   "name": "conda_mxnet_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
